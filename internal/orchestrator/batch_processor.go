package orchestrator

import (
	"context"
	"fmt"
	"math/rand"
	"os"
	"strings"
	"sync"
	"sync/atomic"
	"time"

	"linkedin-crawler/internal/auth"
	"linkedin-crawler/internal/crawler"
	"linkedin-crawler/internal/database"
	"linkedin-crawler/internal/models"
)

// BatchProcessor handles batch processing of emails
type BatchProcessor struct {
	autoCrawler      *AutoCrawler
	tokenExtractor   *auth.TokenExtractor
	queryService     *crawler.QueryService
	validatorService *crawler.ValidatorService
}

// NewBatchProcessor creates a new BatchProcessor instance
func NewBatchProcessor(ac *AutoCrawler) *BatchProcessor {
	return &BatchProcessor{
		autoCrawler:      ac,
		tokenExtractor:   auth.NewTokenExtractor(),
		queryService:     crawler.NewQueryService(),
		validatorService: crawler.NewValidatorService(),
	}
}

// ProcessAllEmails processes all emails with improved token rotation
func (bp *BatchProcessor) ProcessAllEmails() error {
	fmt.Println("üîÑ Phase 1: X·ª≠ l√Ω t·∫•t c·∫£ emails v·ªõi token rotation...")

	stateManager := bp.autoCrawler.stateManager

	// Main loop - continue until no emails left or no accounts left
	for stateManager.HasEmailsToProcess() {
		if atomic.LoadInt32(bp.autoCrawler.GetShutdownRequested()) == 1 {
			fmt.Println("‚ö†Ô∏è Nh·∫≠n t√≠n hi·ªáu d·ª´ng, tho√°t kh·ªèi v√≤ng l·∫∑p ch√≠nh")
			break
		}

		// Display current status
		remaining := stateManager.CountRemainingEmails()
		fmt.Printf("\n" + strings.Repeat("‚îÄ", 60) + "\n")
		fmt.Printf("üîë C·∫¶N TOKENS M·ªöI - Ki·ªÉm tra tokens hi·ªán c√≥...\n")
		bp.autoCrawler.PrintCurrentStats()
		fmt.Printf("üìß C√≤n l·∫°i: %d emails ch∆∞a x·ª≠ l√Ω\n", remaining)
		fmt.Printf("üìÇ Account index hi·ªán t·∫°i: %d/%d\n", bp.autoCrawler.GetUsedAccountIndex(), len(bp.autoCrawler.GetAccounts()))

		// STEP 1: Check if there are available tokens
		var validTokens []string
		config := bp.autoCrawler.GetConfig()
		_, tokenStorage, _ := bp.autoCrawler.GetStorageServices()

		if bp.hasValidTokens() {
			fmt.Println("üîç Ph√°t hi·ªán c√≥ tokens kh·∫£ d·ª•ng, ƒëang load v√† validate...")
			existingTokens, err := tokenStorage.LoadTokensFromFile(config.TokensFilePath)
			if err == nil && len(existingTokens) > 0 {
				fmt.Printf("üìÇ T√¨m th·∫•y %d tokens trong file, ƒëang ki·ªÉm tra chi ti·∫øt...\n", len(existingTokens))
				validTokens, err = bp.validateExistingTokens(existingTokens)
				if err != nil {
					fmt.Printf("‚ö†Ô∏è L·ªói khi ki·ªÉm tra tokens: %v\n", err)
					validTokens = []string{}
				}
			}
		} else {
			fmt.Println("üîç Kh√¥ng c√≥ tokens kh·∫£ d·ª•ng trong file, c·∫ßn l·∫•y tokens m·ªõi")
		}

		// STEP 2: If not enough tokens, get more from accounts
		if len(validTokens) < config.MinTokens {
			fmt.Printf("üìä C√≥ %d tokens h·ª£p l·ªá, c·∫ßn th√™m %d tokens\n",
				len(validTokens), config.MinTokens-len(validTokens))

			// Check if there are accounts left
			if bp.autoCrawler.GetUsedAccountIndex() >= len(bp.autoCrawler.GetAccounts()) {
				fmt.Println("‚ùå ƒê√£ h·∫øt accounts ƒë·ªÉ l·∫•y tokens!")
				if len(validTokens) > 0 {
					fmt.Printf("üîã S·ª≠ d·ª•ng %d tokens c√≤n l·∫°i...\n", len(validTokens))
				} else {
					fmt.Println("üíÄ Kh√¥ng c√≤n tokens n√†o, d·ª´ng ch∆∞∆°ng tr√¨nh")
					break
				}
			} else {
				fmt.Printf("üîÑ L·∫•y th√™m tokens t·ª´ accounts (c√≤n %d accounts)\n",
					len(bp.autoCrawler.GetAccounts())-bp.autoCrawler.GetUsedAccountIndex())

				newTokens, err := bp.getTokensBatch()
				if err != nil {
					fmt.Printf("‚ùå L·ªói l·∫•y tokens: %v\n", err)
					if len(validTokens) == 0 {
						break
					}
				} else {
					// Merge old and new tokens
					allTokens := append(validTokens, newTokens...)
					validTokens = allTokens

					// Save all tokens to file
					if err := tokenStorage.SaveTokensToFile(config.TokensFilePath, validTokens); err != nil {
						fmt.Printf("‚ö†Ô∏è L·ªói l∆∞u tokens: %v\n", err)
					}
					fmt.Printf("‚úÖ T·ªïng c·ªông c√≥ %d tokens ƒë·ªÉ s·ª≠ d·ª•ng\n", len(validTokens))
				}
			}
		} else {
			fmt.Printf("‚úÖ ƒê·ªß tokens (%d) ƒë·ªÉ ti·∫øp t·ª•c crawling\n", len(validTokens))
		}

		// STEP 3: Crawl with current tokens
		if len(validTokens) > 0 {
			fmt.Printf("‚ñ∂Ô∏è B·∫ÆT ƒê·∫¶U CRAWLING v·ªõi %d tokens...\n", len(validTokens))
			fmt.Printf(strings.Repeat("‚îÄ", 60) + "\n\n")

			if err := bp.processEmailsWithTokens(validTokens); err != nil {
				fmt.Printf("‚ö†Ô∏è L·ªói khi x·ª≠ l√Ω emails: %v\n", err)
			}

			// Check if need to get more tokens
			if stateManager.HasEmailsToProcess() {
				fmt.Println("üîÑ C√≤n emails ch∆∞a x·ª≠ l√Ω, chu·∫©n b·ªã l·∫•y tokens m·ªõi...")
				time.Sleep(5 * time.Second) // Short break before getting new tokens
				continue
			}
		} else {
			fmt.Println("‚ùå Kh√¥ng c√≥ tokens n√†o kh·∫£ d·ª•ng, d·ª´ng ch∆∞∆°ng tr√¨nh")
			break
		}

		// If no emails left, exit
		if !stateManager.HasEmailsToProcess() {
			fmt.Println("‚úÖ ƒê√£ x·ª≠ l√Ω h·∫øt emails!")
			break
		}
	}

	return nil
}

// hasValidTokens checks if there are valid tokens available
func (bp *BatchProcessor) hasValidTokens() bool {
	config := bp.autoCrawler.GetConfig()
	outputFile := bp.autoCrawler.GetOutputFile()
	totalEmails := bp.autoCrawler.GetTotalEmails()

	return bp.validatorService.HasValidTokens(config, outputFile, totalEmails)
}

// validateExistingTokens validates existing tokens from file
func (bp *BatchProcessor) validateExistingTokens(tokens []string) ([]string, error) {
	config := bp.autoCrawler.GetConfig()
	outputFile := bp.autoCrawler.GetOutputFile()
	totalEmails := bp.autoCrawler.GetTotalEmails()

	return bp.validatorService.ValidateExistingTokens(tokens, config, outputFile, totalEmails)
}

// validateTokensBatch validates a batch of tokens immediately after extraction
func (bp *BatchProcessor) validateTokensBatch(tokens []string) ([]string, error) {
	config := bp.autoCrawler.GetConfig()
	outputFile := bp.autoCrawler.GetOutputFile()
	totalEmails := bp.autoCrawler.GetTotalEmails()

	return bp.validatorService.ValidateTokensBatch(tokens, config, outputFile, totalEmails)
}

// getTokensBatch gets a batch of tokens from accounts
func (bp *BatchProcessor) getTokensBatch() ([]string, error) {
	var validTokens []string
	config := bp.autoCrawler.GetConfig()
	accounts := bp.autoCrawler.GetAccounts()
	usedIndex := bp.autoCrawler.GetUsedAccountIndex()
	tokensNeeded := config.MaxTokens

	fmt.Printf("üéØ M·ª•c ti√™u: L·∫•y %d tokens m·ªõi\n", tokensNeeded)

	if usedIndex >= len(accounts) {
		return validTokens, fmt.Errorf("no more accounts available (used: %d/%d)",
			usedIndex, len(accounts))
	}

	// Calculate needed accounts - usually need 2-3 accounts for 1 successful token
	accountsNeeded := tokensNeeded * 3 // Buffer because not every account will succeed

	endIndex := usedIndex + accountsNeeded
	if endIndex > len(accounts) {
		endIndex = len(accounts)
	}

	accountsBatch := accounts[usedIndex:endIndex]
	fmt.Printf("üîÑ S·ª≠ d·ª•ng %d accounts (t·ª´ index %d ƒë·∫øn %d) ƒë·ªÉ l·∫•y %d tokens\n",
		len(accountsBatch), usedIndex, endIndex-1, tokensNeeded)

	// Process in small batches to avoid overload
	batchSize := 3
	processedAccounts := 0

	for i := 0; i < len(accountsBatch) && len(validTokens) < tokensNeeded; i += batchSize {
		if atomic.LoadInt32(bp.autoCrawler.GetShutdownRequested()) == 1 {
			fmt.Println("‚ö†Ô∏è Nh·∫≠n t√≠n hi·ªáu d·ª´ng trong qu√° tr√¨nh l·∫•y tokens")
			break
		}

		end := i + batchSize
		if end > len(accountsBatch) {
			end = len(accountsBatch)
		}

		batch := accountsBatch[i:end]
		fmt.Printf("  üì¶ X·ª≠ l√Ω batch %d-%d (c·∫ßn th√™m %d tokens)...\n",
			i+1, end, tokensNeeded-len(validTokens))

		// Get tokens from this batch
		rawTokens := bp.processAccountsBatch(batch)
		processedAccounts += len(batch)

		// Validate tokens immediately
		if len(rawTokens) > 0 {
			fmt.Printf("  üîç Ki·ªÉm tra %d tokens v·ª´a l·∫•y ƒë∆∞·ª£c...\n", len(rawTokens))
			validatedTokens, err := bp.validateTokensBatch(rawTokens)
			if err != nil {
				fmt.Printf("  ‚ö†Ô∏è L·ªói khi validate tokens: %v\n", err)
			} else {
				fmt.Printf("  ‚úÖ C√≥ %d/%d tokens h·ª£p l·ªá t·ª´ batch n√†y\n",
					len(validatedTokens), len(rawTokens))
				validTokens = append(validTokens, validatedTokens...)
			}
		}

		// Update index to not reuse processed accounts
		bp.autoCrawler.SetUsedAccountIndex(bp.autoCrawler.GetUsedAccountIndex() + len(batch))

		// Display progress
		fmt.Printf("  üìä Ti·∫øn ƒë·ªô: %d/%d tokens | ƒê√£ d√πng %d/%d accounts\n",
			len(validTokens), tokensNeeded, bp.autoCrawler.GetUsedAccountIndex(), len(accounts))

		// If enough tokens, stop
		if len(validTokens) >= tokensNeeded {
			fmt.Printf("  üéâ ƒê√£ ƒë·ªß %d tokens!\n", len(validTokens))
			break
		}

		// Rest between batches (except last batch)
		if end < len(accountsBatch) && len(validTokens) < tokensNeeded {
			fmt.Println("  ‚è≥ Ch·ªù 10 gi√¢y tr∆∞·ªõc batch ti·∫øp theo...")
			time.Sleep(10 * time.Second)
		}
	}

	fmt.Printf("‚úÖ K·∫øt qu·∫£: L·∫•y ƒë∆∞·ª£c %d/%d tokens t·ª´ %d accounts\n",
		len(validTokens), tokensNeeded, processedAccounts)

	return validTokens, nil
}

// processAccountsBatch processes a batch of accounts to get tokens
func (bp *BatchProcessor) processAccountsBatch(accounts []models.Account) []string {
	config := bp.autoCrawler.GetConfig()
	results := bp.tokenExtractor.ExtractTokensBatch(accounts, config.AccountsFilePath)

	var validTokens []string
	for _, result := range results {
		if result.Error == nil && result.Token != "" {
			validTokens = append(validTokens, result.Token)
		}
	}
	return validTokens
}

// processEmailsWithTokens processes emails with the given tokens
func (bp *BatchProcessor) processEmailsWithTokens(tokens []string) error {
	if err := bp.initializeCrawler(tokens); err != nil {
		return fmt.Errorf("failed to initialize crawler: %w", err)
	}
	defer func() {
		crawlerInstance := bp.autoCrawler.GetCrawler()
		if crawlerInstance != nil {
			crawler.Close(crawlerInstance) // Use function instead of method
			bp.autoCrawler.SetCrawler(nil)
		}
	}()

	// Get remaining emails (DO NOT reset to 0)
	stateManager := bp.autoCrawler.stateManager
	remainingEmails := stateManager.GetRemainingEmails()

	if len(remainingEmails) == 0 {
		fmt.Println("‚úÖ Kh√¥ng c√≤n emails n√†o c·∫ßn x·ª≠ l√Ω")
		return nil
	}

	fmt.Printf("üéØ Ti·∫øp t·ª•c crawl %d emails c√≤n l·∫°i v·ªõi %d tokens...\n", len(remainingEmails), len(tokens))

	processedCount, err := bp.crawlWithCurrentTokens(remainingEmails)

	fmt.Printf("‚úÖ ƒê√£ x·ª≠ l√Ω %d emails trong batch n√†y\n", processedCount)
	return err
}

// initializeCrawler initializes the LinkedIn crawler with tokens
func (bp *BatchProcessor) initializeCrawler(tokens []string) error {
	config := bp.autoCrawler.GetConfig()
	outputFile := bp.autoCrawler.GetOutputFile()

	newCrawler, err := crawler.New(config, outputFile)
	if err != nil {
		return fmt.Errorf("failed to create crawler: %w", err)
	}

	newCrawler.Tokens = tokens
	newCrawler.InvalidTokens = make(map[string]bool)
	newCrawler.TokensFilePath = config.TokensFilePath
	newCrawler.RateLimitedEmails = []string{}

	bp.autoCrawler.SetCrawler(newCrawler)

	fmt.Printf("‚úÖ Crawler ƒë√£ s·∫µn s√†ng v·ªõi %d tokens\n", len(tokens))
	return nil
}

// crawlWithCurrentTokens crawls emails with current tokens
func (bp *BatchProcessor) crawlWithCurrentTokens(emails []string) (int, error) {
	if len(emails) == 0 {
		return 0, nil
	}

	totalOriginalEmails := len(bp.autoCrawler.GetTotalEmails())
	withData, withoutData, _, _ := bp.autoCrawler.GetEmailMaps()
	alreadyProcessed := len(withData) + len(withoutData)

	fmt.Printf("üéØ B·∫Øt ƒë·∫ßu crawl %d emails v·ªõi tokens hi·ªán t·∫°i...\n", len(emails))
	fmt.Printf("üìä Ti·∫øn ƒë·ªô t·ªïng th·ªÉ: ƒê√£ ho√†n th√†nh %d/%d emails (%.1f%%)\n",
		alreadyProcessed, totalOriginalEmails, float64(alreadyProcessed)*100/float64(totalOriginalEmails))

	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	// Reset stats cho batch n√†y
	crawlerInstance := bp.autoCrawler.GetCrawler()
	if crawlerInstance != nil {
		atomic.StoreInt32(&crawlerInstance.Stats.Processed, 0)
		atomic.StoreInt32(&crawlerInstance.Stats.Success, 0)
		atomic.StoreInt32(&crawlerInstance.Stats.Failed, 0)
		atomic.StoreInt32(&crawlerInstance.Stats.TokenErrors, 0)
		crawlerInstance.AllTokensFailed = false
	}

	emailCh := make(chan string, 100)
	done := make(chan struct{})

	// Status ticker
	statusTicker := time.NewTicker(1 * time.Second)
	go func() {
		defer statusTicker.Stop()
		lastDisplay := ""
		isFirstDisplay := true

		for {
			select {
			case <-ctx.Done():
				if !isFirstDisplay {
					fmt.Fprintf(os.Stderr, "\r\033[A\033[K\033[K\r")
				}
				fmt.Println()
				return
			case <-statusTicker.C:
				// Check token status
				allTokensFailed := false
				validTokenCount := 0
				totalTokens := 0
				batchProcessed := int32(0)
				batchSuccess := int32(0)
				batchFailed := int32(0)
				activeReqs := int32(0)

				crawlerInstance := bp.autoCrawler.GetCrawler()
				if crawlerInstance != nil {
					allTokensFailed = crawlerInstance.AllTokensFailed
					batchProcessed = atomic.LoadInt32(&crawlerInstance.Stats.Processed)
					batchSuccess = atomic.LoadInt32(&crawlerInstance.Stats.Success)
					batchFailed = atomic.LoadInt32(&crawlerInstance.Stats.Failed)
					activeReqs = atomic.LoadInt32(&crawlerInstance.ActiveRequests)
					totalTokens = len(crawlerInstance.Tokens)

					// Count valid tokens
					for _, token := range crawlerInstance.Tokens {
						if !crawlerInstance.InvalidTokens[token] {
							validTokenCount++
						}
					}
				}

				// If tokens failed, stop crawling to get new tokens
				if allTokensFailed {
					fmt.Printf("\n‚ùå T·∫•t c·∫£ tokens ƒë√£ h·∫øt hi·ªáu l·ª±c, c·∫ßn l·∫•y tokens m·ªõi\n")
					cancel() // Stop current crawling
					return
				}

				// Display progress
				withDataCount, withoutDataCount, failedCount, permanentFailedCount := bp.autoCrawler.GetEmailMaps()
				totalProcessedGlobal := len(withDataCount) + len(withoutDataCount)

				batchPercent := 0.0
				if len(emails) > 0 {
					batchPercent = float64(batchProcessed) * 100 / float64(len(emails))
				}

				totalPercent := float64(totalProcessedGlobal) * 100 / float64(totalOriginalEmails)

				// Progress bar
				barWidth := 25
				completedWidth := int(float64(barWidth) * batchPercent / 100)
				bar := "["
				for i := 0; i < barWidth; i++ {
					if i < completedWidth {
						bar += "‚ñà"
					} else if i == completedWidth && batchPercent > 0 && completedWidth < barWidth {
						bar += "‚ñì"
					} else {
						bar += "‚ñë"
					}
				}
				bar += "]"

				line1 := fmt.Sprintf("üîÑ Batch: %s %.1f%% (%d/%d) | Success: %d | Failed: %d | Active: %d | Tokens: %d/%d",
					bar, batchPercent, batchProcessed, len(emails), batchSuccess, batchFailed, activeReqs, validTokenCount, totalTokens)

				line2 := fmt.Sprintf("üìä Total: %.1f%% (%d/%d) | ‚úÖData: %d | üì≠NoData: %d | ‚ùåFailed: %d | üíÄPermanent: %d",
					totalPercent, totalProcessedGlobal, totalOriginalEmails,
					len(withDataCount), len(withoutDataCount), len(failedCount), len(permanentFailedCount))

				newDisplay := line1 + "\n" + line2

				if newDisplay != lastDisplay {
					if !isFirstDisplay {
						fmt.Fprintf(os.Stderr, "\r\033[A\033[K\033[K")
					}
					fmt.Fprintf(os.Stderr, "%s\n%s", line1, line2)
					lastDisplay = newDisplay
					isFirstDisplay = false
				}
			}
		}
	}()

	// Producer goroutine
	go func() {
		defer close(emailCh)
		for _, email := range emails {
			select {
			case <-ctx.Done():
				return
			case emailCh <- email:
			}
		}
	}()

	// Consumer goroutines
	go func() {
		defer close(done)
		var wg sync.WaitGroup
		config := bp.autoCrawler.GetConfig()
		maxConcurrency := int(config.MaxConcurrency)

		for i := 0; i < maxConcurrency; i++ {
			wg.Add(1)
			go func() {
				defer wg.Done()
				for email := range emailCh {
					select {
					case <-ctx.Done():
						return
					default:
					}

					if atomic.LoadInt32(bp.autoCrawler.GetShutdownRequested()) == 1 {
						return
					}

					// Check tokens before processing email
					crawlerInstance := bp.autoCrawler.GetCrawler()
					if crawlerInstance != nil {
						allTokensFailed := crawlerInstance.AllTokensFailed
						if allTokensFailed {
							fmt.Printf("\n‚ùå Tokens h·∫øt hi·ªáu l·ª±c trong qu√° tr√¨nh crawl, d·ª´ng worker\n")
							cancel()
							return
						}

						atomic.AddInt32(&crawlerInstance.Stats.Processed, 1)
						success := bp.retryEmailWithNewLogic(email, 5)

						if !success {
							bp.autoCrawler.LogLine(fmt.Sprintf("üíæ Email %s th·∫•t b·∫°i sau 5 l·∫ßn retry - gi·ªØ l·∫°i trong file", email))
						}
					}
				}
			}()
		}
		wg.Wait()
	}()

	// Wait for completion
	select {
	case <-done:
		statusTicker.Stop()
		fmt.Fprintf(os.Stderr, "\r\033[A\033[K\033[K\r")
		fmt.Println()

		processed := int32(0)
		success := int32(0)
		failed := int32(0)
		crawlerInstance := bp.autoCrawler.GetCrawler()
		if crawlerInstance != nil {
			processed = atomic.LoadInt32(&crawlerInstance.Stats.Processed)
			success = atomic.LoadInt32(&crawlerInstance.Stats.Success)
			failed = atomic.LoadInt32(&crawlerInstance.Stats.Failed)
		}

		fmt.Printf("‚úÖ Ho√†n th√†nh batch: Processed: %d | Success: %d | Failed: %d\n", processed, success, failed)

		withData, withoutData, _, _ := bp.autoCrawler.GetEmailMaps()
		fmt.Printf("üìä Current totals: ‚úÖData: %d | üì≠NoData: %d\n", len(withData), len(withoutData))

		return int(processed), nil

	case <-ctx.Done():
		statusTicker.Stop()
		fmt.Fprintf(os.Stderr, "\r\033[A\033[K\033[K\r")
		fmt.Println()

		bp.autoCrawler.stateManager.UpdateEmailsFile()

		processed := int32(0)
		crawlerInstance := bp.autoCrawler.GetCrawler()
		if crawlerInstance != nil {
			processed = atomic.LoadInt32(&crawlerInstance.Stats.Processed)
		}

		if atomic.LoadInt32(bp.autoCrawler.GetShutdownRequested()) == 1 {
			fmt.Printf("‚ö†Ô∏è Crawling b·ªã d·ª´ng do Ctrl+C: ƒê√£ x·ª≠ l√Ω %d emails\n", processed)
		} else {
			fmt.Printf("üîÑ Crawling t·∫°m d·ª´ng ƒë·ªÉ l·∫•y tokens m·ªõi: ƒê√£ x·ª≠ l√Ω %d emails\n", processed)
		}
		return int(processed), ctx.Err()
	}
}

// Updated internal/orchestrator/batch_processor.go - Key method
func (bp *BatchProcessor) retryEmailWithNewLogic(email string, maxRetries int) bool {
	config := bp.autoCrawler.GetConfig()
	crawlerInstance := bp.autoCrawler.GetCrawler()
	dbStorage := bp.autoCrawler.GetDBStorage()

	for attempt := 1; attempt <= maxRetries; attempt++ {
		if atomic.LoadInt32(bp.autoCrawler.GetShutdownRequested()) == 1 {
			return false
		}

		if crawlerInstance != nil {
			allTokensFailed := crawlerInstance.AllTokensFailed
			if allTokensFailed {
				bp.autoCrawler.LogLine(fmt.Sprintf("‚ùå T·∫•t c·∫£ tokens ƒë√£ b·ªã l·ªói, d·ª´ng retry cho email: %s", email))
				return false
			}

			reqCtx, reqCancel := context.WithTimeout(context.Background(), config.RequestTimeout)
			hasProfile, body, statusCode, _ := bp.queryService.QueryProfileWithRetryLogic(crawlerInstance, reqCtx, email)
			reqCancel()

			// Log attempt
			snippet := ""
			if len(body) > 200 {
				snippet = string(body[:200]) + "..."
			} else {
				snippet = string(body)
			}

			bp.autoCrawler.LogLine(fmt.Sprintf("Retry %d/%d - Email: %s | Status: %d | Response: %s",
				attempt, maxRetries, email, statusCode, snippet))

			// Distinguish between data and no data
			if statusCode == 200 {
				if hasProfile {
					// Check if there's actual profile data
					profileExtractor := crawler.NewProfileExtractor()
					profile, parseErr := profileExtractor.ExtractProfileData(body)
					if parseErr == nil && profile.User != "" && profile.User != "null" && profile.User != "{}" {
						// HAS LINKEDIN INFO - Update database
						if err := dbStorage.EmailRepo.UpdateEmailWithProfile(email, profile); err != nil {
							bp.autoCrawler.LogLine(fmt.Sprintf("‚ö†Ô∏è L·ªói update database: %v", err))
						}

						bp.autoCrawler.LogLine(fmt.Sprintf("‚úÖ Email c√≥ th√¥ng tin LinkedIn: %s | User: %s | URL: %s",
							email, profile.User, profile.LinkedInURL))

						// Write to hit.txt file
						profileExtractor.WriteProfileToFile(crawlerInstance, email, profile)
						atomic.AddInt32(&crawlerInstance.Stats.Success, 1)
					} else {
						// NO LINKEDIN INFO - Update database
						if err := dbStorage.EmailRepo.UpdateEmailStatus(email, database.EmailStatusSuccessNoData); err != nil {
							bp.autoCrawler.LogLine(fmt.Sprintf("‚ö†Ô∏è L·ªói update database: %v", err))
						}

						bp.autoCrawler.LogLine(fmt.Sprintf("üì≠ Email kh√¥ng c√≥ th√¥ng tin LinkedIn: %s", email))
						atomic.AddInt32(&crawlerInstance.Stats.Success, 1)
					}
				} else {
					// NO LINKEDIN INFO - Update database
					if err := dbStorage.EmailRepo.UpdateEmailStatus(email, database.EmailStatusSuccessNoData); err != nil {
						bp.autoCrawler.LogLine(fmt.Sprintf("‚ö†Ô∏è L·ªói update database: %v", err))
					}

					bp.autoCrawler.LogLine(fmt.Sprintf("üì≠ Email kh√¥ng c√≥ th√¥ng tin LinkedIn: %s", email))
					atomic.AddInt32(&crawlerInstance.Stats.Success, 1)
				}

				return true
			}

			// If not last attempt and not successful, wait before retry
			if attempt < maxRetries {
				// Random delay between 100-500ms
				r := rand.New(rand.NewSource(time.Now().UnixNano()))
				delayMs := 200 + r.Intn(401)
				delay := time.Duration(delayMs) * time.Millisecond

				bp.autoCrawler.LogLine(fmt.Sprintf("‚è≥ Ch·ªù %dms tr∆∞·ªõc khi retry l·∫ßn %d cho email: %s", delayMs, attempt+1, email))
				time.Sleep(delay)
			}
		}
	}

	// After retrying 5 times and still not successful - Update database
	if err := dbStorage.EmailRepo.UpdateEmailStatus(email, database.EmailStatusFailed); err != nil {
		bp.autoCrawler.LogLine(fmt.Sprintf("‚ö†Ô∏è L·ªói update database: %v", err))
	}

	// Increment retry count in database
	if err := dbStorage.EmailRepo.IncrementRetryCount(email, "Failed after max retries"); err != nil {
		bp.autoCrawler.LogLine(fmt.Sprintf("‚ö†Ô∏è L·ªói update retry count: %v", err))
	}

	bp.autoCrawler.LogLine(fmt.Sprintf("‚ùå Email %s th·∫•t b·∫°i sau %d l·∫ßn retry", email, maxRetries))

	crawlerInstance = bp.autoCrawler.GetCrawler()
	if crawlerInstance != nil {
		atomic.AddInt32(&crawlerInstance.Stats.Failed, 1)
	}
	return false
}
